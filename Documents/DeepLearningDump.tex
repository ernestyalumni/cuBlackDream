% file: DeepLearning_dump.tex
% Deep Learning, in unconventional ``grande'' format; fitting a widescreen format
% 
% github        : ernestyalumni
% linkedin      : ernestyalumni 
% wordpress.com : ernestyalumni
%
% This code is open-source, governed by the Creative Common license.  Use of this code is governed by the Caltech Honor Code: ``No member of the Caltech community shall take unfair advantage of any other member of the Caltech community.'' 
% 

\documentclass[10pt]{amsart}
\pdfoutput=1
%\usepackage{mathtools,amssymb,lipsum,caption}
\usepackage{mathtools,amssymb,caption}


\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage[table]{xcolor}
\usepackage{pdfpages}
%\usepackage[version=3]{mhchem}
%\usepackage{mhchem}

\usepackage{tikz}
\usetikzlibrary{matrix,arrows,backgrounds} % background for framed option
\usetikzlibrary{arrows.meta}
\usetikzlibrary{cd}

\usepackage{multicol}

% ----------------------------------------------------------------------------------------
% 20180203

\usetikzlibrary{calc}

% ----------------------------------------------------------------------------------------


\hypersetup{colorlinks=true,citecolor=[rgb]{0,0.4,0}}

\oddsidemargin=15pt
\evensidemargin=5pt
\hoffset-45pt
\voffset-55pt
\topmargin=-4pt
\headsep=5pt
\textwidth=1120pt
\textheight=595pt
\paperwidth=1200pt
\paperheight=700pt
\footskip=40pt


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{axiom}{Axiom}
%\newtheorem*{main}{Main Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}

\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof:}\space#1}{\hfill $\blacksquare$}

%This defines a new command \questionhead which takes one argument and
%prints out Question #. with some space.
\newcommand{\questionhead}[1]
{\bigskip\bigskip
	\noindent{\small\bf Question #1.}
	\bigskip}

\newcommand{\problemhead}[1]
{
	\noindent{\small\bf Problem #1.}
}

\newcommand{\exercisehead}[1]
{ \smallskip
	\noindent{\small\bf Exercise #1.}
}

\newcommand{\solutionhead}[1]
{
	\noindent{\small\bf Solution #1.}
}

\title{The Deep Learning Dump}
\author{Ernest Yeung \href{mailto:ernestyalumni@gmail.com}{ernestyalumni@gmail.com}}
\date{19 July 2023}
\keywords{Deep Learning, Deep Neural Networks}
\begin{document}
	
\definecolor{darkgreen}{rgb}{0,0.4,0}
\lstset{language=Python,
	frame=bottomline,
	basicstyle=\scriptsize,
	identifierstyle=\color{blue},
	keywordstyle=\bfseries,
	commentstyle=\color{darkgreen},
	stringstyle=\color{red},
}
%\lstlistoflistings
	
\maketitle
	
From the beginning of 2016, I decided to cease all explicit crowdfunding for any of my materials on physics, math.  I failed to raise \emph{any} funds from previous crowdfunding efforts.  I decided that if I was going to live in \emph{abundance}, I must lose a scarcity attitude.  I am committed to keeping all of my material \textbf{open-sourced}.  I give all my stuff \emph{for free}.   
	
In the beginning of 2017, I received a very generous donation from a reader from Norway who found these notes useful, through \emph{PayPal}.  If you find these notes useful, feel free to donate directly and easily through \href{https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=ernestsaveschristmas%2bpaypal%40gmail%2ecom&lc=US&item_name=ernestyalumni&currency_code=USD&bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted}{PayPal}. PayPal does charge a fee, so I also have a Venmo, \href{https://account.venmo.com/u/ernestyalumni}{ernestyalumni}, and CashApp (via email \url{mailto:ernestyalumni@gmail.com}).

Otherwise, under the \emph{open-source MIT license}, feel free to copy, edit, paste, make your own versions, share, use as you wish.    

\noindent gmail        : ernestyalumni \\
linkedin     : ernestyalumni \\
twitter      : ernestyalumni \\

		
\begin{multicols*}{2}
		
\setcounter{tocdepth}{1}
\tableofcontents
		
\begin{abstract}
Everything Deep Learning, Deep Neural Networks
\end{abstract}
		
\part{Deep Neural Networks}

\section{Gaussian Processes}
Yang (2021) for Tensor Programs I\cite{Yang2021}



\end{multicols*}


\begin{thebibliography}{9}

\bibitem{Yang2021} 
Greg Yang. "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes." \href{https://arxiv.org/pdf/1910.12478.pdf}{arXiv:1910.12478v3} 8 May 2021

\end{thebibliography}
\end{document}
