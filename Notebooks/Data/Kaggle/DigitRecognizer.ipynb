{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfca065c",
   "metadata": {},
   "source": [
    "# Setup Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e674dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "notebook_directory_parent = Path.cwd().resolve().parent.parent.parent\n",
    "if str(notebook_directory_parent) not in sys.path:\n",
    "    sys.path.append(str(notebook_directory_parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7e86e",
   "metadata": {},
   "source": [
    "# Setup to use Python libraries/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e87943",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from CuISOX.DataWrangling.Kaggle.DigitRecognizer import ProcessDigitsData\n",
    "from CuISOX.utilities.configure_paths import DataPaths\n",
    "from CuISOX.utilities.DataIO.KagglePaths import KagglePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478ea1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbfce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = DataPaths()\n",
    "kaggle_paths = KagglePaths()\n",
    "kaggle_data_file_paths = kaggle_paths.get_all_data_file_paths()\n",
    "digit_paths = kaggle_data_file_paths[\"DigitRecognizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3071ce0",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "See [Long-Short Term Memory with Pytorch](https://www.kaggle.com/code/kanncaa1/long-short-term-memory-with-pytorch)\n",
    "\n",
    "Let's first locate where our data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81629d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cuBlackDream/Data/Kaggle/DigitRecognizer/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "training_data_paths = DataPaths.get_path_with_substring(digit_paths, \"train\")\n",
    "training_data_path = data_paths.Kaggle() / training_data_paths[0]\n",
    "print(training_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62838dce",
   "metadata": {},
   "source": [
    "We can also find the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7b9641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DigitRecognizer': [PosixPath('DigitRecognizer/digit-recognizer/sample_submission.csv'), PosixPath('DigitRecognizer/digit-recognizer/test.csv'), PosixPath('DigitRecognizer/digit-recognizer/train.csv')]}\n",
      "/cuBlackDream/Data/Kaggle/DigitRecognizer/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "print(kaggle_data_file_paths)\n",
    "testing_data_paths = DataPaths.get_path_with_substring(digit_paths, \"test\")\n",
    "testing_data_path = data_paths.Kaggle() / testing_data_paths[0]\n",
    "print(testing_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a065afe",
   "metadata": {},
   "source": [
    "## Loading **Training** Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415f4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses a module that does all the subsequent, following, steps.Those steps were done to\n",
    "# explicitly show each step. Either use the module that wraps up all those steps or step\n",
    "# through the steps.\n",
    "\n",
    "process_digits_data = ProcessDigitsData()\n",
    "\n",
    "process_digits_data.parse_csv(training_data_path)\n",
    "process_digits_data.load_data()\n",
    "\n",
    "print(len(process_digits_data.training_loader.dataset))\n",
    "print(len(process_digits_data.test_loader.dataset))\n",
    "\n",
    "assert (len(process_digits_data.training_loader.dataset) == 33600)\n",
    "assert (len(process_digits_data.test_loader.dataset) == 8400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ab6b3",
   "metadata": {},
   "source": [
    "Starting from here are all the steps, explicitly shown, as the same as using ProcessDigitsData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9350dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(training_data_path, dtype= np.float32)\n",
    "print(train.columns.tolist())\n",
    "print(train.size)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd72977",
   "metadata": {},
   "source": [
    "Split data into features(pixesl) and labels (numbers from 0 to 9)\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "In this case, y is \"categorical\" data, such that y can be from 0, 1, to 9; i.e. y is a non-negative integer.\n",
    "X in this case has D = 784 features and we normalize by 255. Each row is a data sample, N = 42000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4703764",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_targets_numpy = train.label.values\n",
    "X_features_numpy = train.loc[:,train.columns != \"label\"].values / 255 # normalization\n",
    "X_features_train, X_features_test, y_targets_train, y_targets_test = train_test_split(\n",
    "    X_features_numpy,\n",
    "    y_targets_numpy,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42)\n",
    "\n",
    "print(type(X_features_train))\n",
    "print(type(X_features_test))\n",
    "print(type(y_targets_train))\n",
    "print(type(y_targets_test))\n",
    "print(X_features_train.shape)\n",
    "print(X_features_test.shape)\n",
    "print(y_targets_train.shape)\n",
    "print(y_targets_test.shape)\n",
    "print(len(X_features_train))\n",
    "print(len(X_features_test))\n",
    "print(len(y_targets_train))\n",
    "print(len(y_targets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7fcd6",
   "metadata": {},
   "source": [
    "Create feature and targets tensor for training set. We need a variable to accumulate gradients. Therefore, first create tensor, and then we'll create variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_training = torch.from_numpy(X_features_train)\n",
    "y_targets_training = torch.from_numpy(y_targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# Create feature and targets tensor for test set.\n",
    "X_features_testing = torch.from_numpy(X_features_test)\n",
    "y_targets_testing = torch.from_numpy(y_targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "print(type(X_features_training), type(y_targets_training))\n",
    "print(X_features_training.shape)\n",
    "print(y_targets_training.shape)\n",
    "print(X_features_training.size())\n",
    "print(y_targets_training.size())\n",
    "print(len(X_features_training))\n",
    "print(len(y_targets_training))\n",
    "print(X_features_testing.shape)\n",
    "print(y_targets_testing.shape)\n",
    "print(X_features_testing.size())\n",
    "print(y_targets_testing.size())\n",
    "print(len(X_features_testing))\n",
    "print(len(y_targets_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6962c",
   "metadata": {},
   "source": [
    "## Model Parameters and Sizes, Configuration\n",
    "\n",
    "Batch size, epoch, and iteration\n",
    "\n",
    "Suppose $B \\equiv$ batch size.\n",
    "\n",
    "Take the total number of samples $N$ and divide by $B$ so to get \"number of batches\". Given $N_{\\text{iters}} \\equiv$ total number of iterations, with each iteration doing 1 batch, we can get the total number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a997614",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = int( n_iters / (len(X_features_training) / batch_size))\n",
    "print(\"Epoch Number: \", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch training and test sets\n",
    "training = TensorDataset(X_features_training, y_targets_training)\n",
    "testing = TensorDataset(X_features_testing, y_targets_testing)\n",
    "\n",
    "# Data Loader\n",
    "training_loader = DataLoader(training, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87384801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize one of the images in data set.\n",
    "plt.imshow(X_features_numpy[42].reshape(28, 28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(y_targets_numpy[42]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf4088",
   "metadata": {},
   "source": [
    "## Exploring Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0aa7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_iterator = enumerate(process_digits_data.training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, (image_batch, batch_labels) = training_data_iterator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff409ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)\n",
    "print(type(image_batch))\n",
    "print(type(batch_labels))\n",
    "print(image_batch.shape)\n",
    "print(batch_labels.shape)\n",
    "print(image_batch.size())\n",
    "print(batch_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65abd7",
   "metadata": {},
   "source": [
    "`.view()` Returns a new tensor with the same data as self tensor but of a different *shape*. See [torch.tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch_transformed = image_batch.view(-1,  28, 28).requires_grad_()\n",
    "print(type(image_batch_transformed))\n",
    "print(image_batch_transformed.shape)\n",
    "print(image_batch_transformed.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06c238",
   "metadata": {},
   "source": [
    "# Exploring Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7df3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cuBlackDream/Data/Kaggle/DigitRecognizer/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "print(testing_data_path)\n",
    "test_X = ProcessDigitsData.parse_csv_no_split(testing_data_path)\n",
    "test_data_loader = ProcessDigitsData.load_data_no_split(test_X, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous work\n",
    "df = pd.read_csv(testing_data_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d5ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
