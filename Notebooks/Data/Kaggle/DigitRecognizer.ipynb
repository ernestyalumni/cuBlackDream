{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfca065c",
   "metadata": {},
   "source": [
    "# Setup Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e674dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "notebook_directory_parent = Path.cwd().resolve().parent.parent.parent\n",
    "if str(notebook_directory_parent) not in sys.path:\n",
    "    sys.path.append(str(notebook_directory_parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7e86e",
   "metadata": {},
   "source": [
    "# Setup to use Python libraries/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e87943",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from CuISOX.DataWrangling.Kaggle.DigitRecognizer import ProcessDigitsData\n",
    "from CuISOX.utilities.configure_paths import DataPaths\n",
    "from CuISOX.utilities.DataIO.KagglePaths import KagglePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "478ea1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbfce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = DataPaths()\n",
    "kaggle_paths = KagglePaths()\n",
    "kaggle_data_file_paths = kaggle_paths.get_all_data_file_paths()\n",
    "digit_paths = kaggle_data_file_paths[\"DigitRecognizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3071ce0",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "See [Long-Short Term Memory with Pytorch](https://www.kaggle.com/code/kanncaa1/long-short-term-memory-with-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81629d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cuBlackDream/Data/Kaggle/DigitRecognizer/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "training_data_paths = DataPaths.get_path_with_substring(digit_paths, \"train\")\n",
    "training_data_path = data_paths.Kaggle() / training_data_paths[0]\n",
    "print(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415f4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600\n",
      "8400\n"
     ]
    }
   ],
   "source": [
    "# This uses a module that does all the subsequent, following, steps.Those steps were done to\n",
    "# explicitly show each step. Either use the module that wraps up all those steps or step\n",
    "# through the steps.\n",
    "\n",
    "process_digits_data = ProcessDigitsData()\n",
    "\n",
    "process_digits_data.parse_csv(training_data_path)\n",
    "process_digits_data.load_data()\n",
    "\n",
    "print(len(process_digits_data.training_loader.dataset))\n",
    "print(len(process_digits_data.test_loader.dataset))\n",
    "\n",
    "assert (len(process_digits_data.training_loader.dataset) == 33600)\n",
    "assert (len(process_digits_data.test_loader.dataset) == 8400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ab6b3",
   "metadata": {},
   "source": [
    "Starting from here are all the steps, explicitly shown, as the same as using ProcessDigitsData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9350dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783']\n",
      "32970000\n",
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(training_data_path, dtype= np.float32)\n",
    "print(train.columns.tolist())\n",
    "print(train.size)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd72977",
   "metadata": {},
   "source": [
    "Split data into features(pixesl) and labels (numbers from 0 to 9)\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "In this case, y is \"categorical\" data, such that y can be from 0, 1, to 9; i.e. y is a non-negative integer.\n",
    "X in this case has D = 784 features and we normalize by 255. Each row is a data sample, N = 42000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4703764",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_targets_numpy = train.label.values\n",
    "X_features_numpy = train.loc[:,train.columns != \"label\"].values / 255 # normalization\n",
    "X_features_train, X_features_test, y_targets_train, y_targets_test = train_test_split(\n",
    "    X_features_numpy,\n",
    "    y_targets_numpy,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7fcd6",
   "metadata": {},
   "source": [
    "Create feature and targets tensor for training set. We need a variable to accumulate gradients. Therefore, first create tensor, and then we'll create variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ae9b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X_features_training = torch.from_numpy(X_features_train)\n",
    "y_targets_training = torch.from_numpy(y_targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# Create feature and targets tensor for test set.\n",
    "X_features_testing = torch.from_numpy(X_features_test)\n",
    "y_targets_testing = torch.from_numpy(y_targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "print(type(X_features_training), type(y_targets_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6962c",
   "metadata": {},
   "source": [
    "## Model Parameters and Sizes, Configuration\n",
    "\n",
    "Batch size, epoch, and iteration\n",
    "\n",
    "Suppose $B \\equiv$ batch size.\n",
    "\n",
    "Take the total number of samples $N$ and divide by $B$ so to get \"number of batches\". Given $N_{\\text{iters}} \\equiv$ total number of iterations, with each iteration doing 1 batch, we can get the total number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a997614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600 torch.Size([33600, 784])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = int( n_iters / (len(X_features_training) / batch_size))\n",
    "print(\"Epoch Number: \", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch training and test sets\n",
    "training = TensorDataset(X_features_training, y_targets_training)\n",
    "testing = TensorDataset(X_features_testing, y_targets_testing)\n",
    "\n",
    "# Data Loader\n",
    "training_loader = DataLoader(training, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87384801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize one of the images in data set.\n",
    "plt.imshow(X_features_numpy[42].reshape(28, 28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(y_targets_numpy[42]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf4088",
   "metadata": {},
   "source": [
    "## Exploring Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0aa7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_iterator = enumerate(process_digits_data.training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e581d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, (image_batch, batch_labels) = training_data_iterator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff409ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(type(image_batch))\n",
    "print(type(batch_labels))\n",
    "print(image_batch.shape)\n",
    "print(batch_labels.shape)\n",
    "print(image_batch.size())\n",
    "print(batch_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65abd7",
   "metadata": {},
   "source": [
    "`.view()` Returns a new tensor with the same data as self tensor but of a different *shape*. See [torch.tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e16e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([100, 28, 28])\n",
      "torch.Size([100, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image_batch_transformed = image_batch.view(-1,  28, 28).requires_grad_()\n",
    "print(type(image_batch_transformed))\n",
    "print(image_batch_transformed.shape)\n",
    "print(image_batch_transformed.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22176f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
