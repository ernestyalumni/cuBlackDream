{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfca065c",
   "metadata": {},
   "source": [
    "# Setup Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e674dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cuBlackDream\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "notebook_directory_parent = Path.cwd().resolve().parent.parent\n",
    "print(notebook_directory_parent)\n",
    "if str(notebook_directory_parent) not in sys.path:\n",
    "    sys.path.append(str(notebook_directory_parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7e86e",
   "metadata": {},
   "source": [
    "# Setup to use Python libraries/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e87943",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from CuISOX.DataWrangling.Kaggle.DigitRecognizer import ProcessDigitsData\n",
    "from CuISOX.PyTorch.RecurrentNeuralNetworks.LSTM.Examples import LSTMWithLinearOutput\n",
    "from CuISOX.utilities.configure_paths import DataPaths\n",
    "from CuISOX.utilities.DataIO.KagglePaths import KagglePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ea1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbfce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = DataPaths()\n",
    "kaggle_paths = KagglePaths()\n",
    "kaggle_data_file_paths = kaggle_paths.get_all_data_file_paths()\n",
    "digit_paths = kaggle_data_file_paths[\"DigitRecognizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3071ce0",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "See [Long-Short Term Memory with Pytorch](https://www.kaggle.com/code/kanncaa1/long-short-term-memory-with-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81629d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cuBlackDream/Data/Kaggle/DigitRecognizer/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "training_data_paths = DataPaths.get_path_with_substring(digit_paths, \"train\")\n",
    "training_data_path = data_paths.Kaggle() / training_data_paths[0]\n",
    "print(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9350dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_digits_data = ProcessDigitsData()\n",
    "\n",
    "process_digits_data.parse_csv(training_data_path)\n",
    "process_digits_data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6962c",
   "metadata": {},
   "source": [
    "## Model Parameters and Sizes, Configuration\n",
    "\n",
    "Batch size, epoch, and iteration\n",
    "\n",
    "Suppose $B \\equiv$ batch size.\n",
    "\n",
    "Take the total number of samples $N$ and divide by $B$ so to get \"number of batches\". Given $N_{\\text{iters}} \\equiv$ total number of iterations, with each iteration doing 1 batch, we can get the total number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a997614",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = int( n_iters / (len(X_features_training) / batch_size))\n",
    "print(\"Epoch Number: \", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87384801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize one of the images in data set.\n",
    "plt.imshow(X_features_numpy[42].reshape(28, 28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(y_targets_numpy[42]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e601c6a",
   "metadata": {},
   "source": [
    "# Run Forward once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92896b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_iterator = enumerate(process_digits_data.training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677e3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "sequence_length = 28\n",
    "# EY: 20230906, we'll use one of the physical dimensions (I'm guessing width) as the \"sequence\" variable. So we\n",
    "# imagine that each row is an input and each successive row makes a sequence of rows of pixels of the image.\n",
    "lstm_with_linear_output = LSTMWithLinearOutput(input_dim, hidden_dim, layer_dim, output_dim, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f2ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, (image_batch, batch_labels) = training_data_iterator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa565bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output, example_loss = lstm_with_linear_output.run_on_image_batch(image_batch, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9260fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([100, 10])\n",
      "torch.Size([])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([])\n",
      "tensor([ 0.0300, -0.1175, -0.1147,  0.0723, -0.0552, -0.0509, -0.0683, -0.0231,\n",
      "        -0.0036, -0.0847], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0351, -0.1163, -0.1216,  0.0764, -0.0520, -0.0583, -0.0689, -0.0247,\n",
      "        -0.0029, -0.0828], grad_fn=<SelectBackward0>)\n",
      "2.2987165451049805\n"
     ]
    }
   ],
   "source": [
    "print(type(example_output))\n",
    "print(type(example_loss))\n",
    "print(example_output.size())\n",
    "print(example_loss.size())\n",
    "print(example_output.shape)\n",
    "print(example_loss.shape)\n",
    "print(example_output[0])\n",
    "print(example_output[1])\n",
    "print(example_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e31a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
