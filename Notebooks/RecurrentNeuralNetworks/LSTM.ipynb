{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfca065c",
   "metadata": {},
   "source": [
    "# Setup Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e674dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cuBlackDream\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "notebook_directory_parent = Path.cwd().resolve().parent.parent\n",
    "print(notebook_directory_parent)\n",
    "if str(notebook_directory_parent) not in sys.path:\n",
    "    sys.path.append(str(notebook_directory_parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7e86e",
   "metadata": {},
   "source": [
    "# Setup to use Python libraries/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e87943",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from CuISOX.DataWrangling.Kaggle.DigitRecognizer import ProcessDigitsData\n",
    "from CuISOX.PyTorch.RecurrentNeuralNetworks.LSTM.Examples import (\n",
    "    LSTMWithLinearOutput,\n",
    "    train_LSTMWithLinearOutput_model_on_images)\n",
    "from CuISOX.utilities.configure_paths import DataPaths\n",
    "from CuISOX.utilities.DataIO.KagglePaths import KagglePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19add4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbfce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = DataPaths()\n",
    "kaggle_paths = KagglePaths()\n",
    "kaggle_data_file_paths = kaggle_paths.get_all_data_file_paths()\n",
    "digit_paths = kaggle_data_file_paths[\"DigitRecognizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3071ce0",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "See [Long-Short Term Memory with Pytorch](https://www.kaggle.com/code/kanncaa1/long-short-term-memory-with-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81629d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cuBlackDream/Data/Kaggle/DigitRecognizer/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "training_data_paths = DataPaths.get_path_with_substring(digit_paths, \"train\")\n",
    "training_data_path = data_paths.Kaggle() / training_data_paths[0]\n",
    "print(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9350dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_digits_data = ProcessDigitsData()\n",
    "\n",
    "process_digits_data.parse_csv(training_data_path)\n",
    "process_digits_data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6962c",
   "metadata": {},
   "source": [
    "## Model Parameters and Sizes, Configuration\n",
    "\n",
    "Batch size, epoch, and iteration\n",
    "\n",
    "Suppose $B \\equiv$ batch size.\n",
    "\n",
    "Take the total number of samples $N$ and divide by $B$ so to get \"number of batches\". Given $N_{\\text{iters}} \\equiv$ total number of iterations, with each iteration doing 1 batch, we can get the total number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a997614",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "# Originally, this value was 6000.\n",
    "n_iters = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87384801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize one of the images in data set.\n",
    "plt.imshow(X_features_numpy[42].reshape(28, 28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(y_targets_numpy[42]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e601c6a",
   "metadata": {},
   "source": [
    "# Run Forward once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92896b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_iterator = enumerate(process_digits_data.training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677e3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "sequence_length = 28\n",
    "# EY: 20230906, we'll use one of the physical dimensions (I'm guessing width) as the \"sequence\" variable. So we\n",
    "# imagine that each row is an input and each successive row makes a sequence of rows of pixels of the image.\n",
    "lstm_with_linear_output = LSTMWithLinearOutput(input_dim, hidden_dim, layer_dim, output_dim, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, (image_batch, batch_labels) = training_data_iterator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa565bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output, example_loss = lstm_with_linear_output.run_on_image_batch(image_batch, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(example_output))\n",
    "print(type(example_loss))\n",
    "print(example_output.size())\n",
    "print(example_loss.size())\n",
    "print(example_output.shape)\n",
    "print(example_loss.shape)\n",
    "print(example_output[0])\n",
    "print(example_output[1])\n",
    "print(example_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value, max_indices = torch.max(example_output.data, 1)\n",
    "print(max_value)\n",
    "print(max_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbabe6e",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518c24ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = process_digits_data.calculate_epoch(n_iters, batch_size)\n",
    "# Originally, the value of number_of_epochs was 17 given n_iters = 6000\n",
    "print(number_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1efe755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.020253779366612434, Accuracy: 97.16666412353516\n",
      "Iteration: 1000, Loss: 0.017194164916872978, Accuracy: 97.42857360839844\n",
      "Iteration: 1500, Loss: 0.005195411387830973, Accuracy: 97.26190185546875\n",
      "Iteration: 2000, Loss: 0.030824439600110054, Accuracy: 97.60713958740234\n",
      "Iteration: 2500, Loss: 0.019372297450900078, Accuracy: 97.60713958740234\n",
      "Iteration: 3000, Loss: 0.03789208084344864, Accuracy: 97.5\n",
      "Iteration: 3500, Loss: 0.04638068377971649, Accuracy: 97.4047622680664\n",
      "Iteration: 4000, Loss: 0.010782229714095592, Accuracy: 97.33333587646484\n",
      "Iteration: 4500, Loss: 0.024220017716288567, Accuracy: 97.63095092773438\n",
      "Iteration: 5000, Loss: 0.010724058374762535, Accuracy: 97.88095092773438\n",
      "Iteration: 5500, Loss: 0.04427080228924751, Accuracy: 97.45237731933594\n",
      "Iteration: 6000, Loss: 0.00602591410279274, Accuracy: 97.77381134033203\n",
      "Iteration: 6500, Loss: 0.007981122471392155, Accuracy: 97.66666412353516\n",
      "Iteration: 7000, Loss: 0.005064698401838541, Accuracy: 97.80952453613281\n",
      "Iteration: 7500, Loss: 0.007194367703050375, Accuracy: 97.94047546386719\n",
      "Iteration: 8000, Loss: 0.11576607078313828, Accuracy: 97.14286041259766\n",
      "Iteration: 8500, Loss: 0.0037536623422056437, Accuracy: 98.0\n",
      "Iteration: 9000, Loss: 0.01658228598535061, Accuracy: 97.83333587646484\n",
      "Iteration: 9500, Loss: 0.001184158492833376, Accuracy: 98.08333587646484\n",
      "Iteration: 10000, Loss: 0.038290202617645264, Accuracy: 97.86904907226562\n",
      "Iteration: 10500, Loss: 0.0016803080216050148, Accuracy: 97.94047546386719\n",
      "Iteration: 11000, Loss: 0.007768956478685141, Accuracy: 97.82142639160156\n",
      "Iteration: 11500, Loss: 0.010689587332308292, Accuracy: 98.03571319580078\n",
      "Iteration: 12000, Loss: 0.003076237393543124, Accuracy: 98.04762268066406\n",
      "Iteration: 12500, Loss: 0.010782444849610329, Accuracy: 97.98809814453125\n",
      "Iteration: 13000, Loss: 0.003744336310774088, Accuracy: 97.79762268066406\n",
      "Iteration: 13500, Loss: 0.006143236067146063, Accuracy: 98.21428680419922\n",
      "Iteration: 14000, Loss: 0.0047658029943704605, Accuracy: 97.98809814453125\n",
      "Iteration: 14500, Loss: 0.0023402394726872444, Accuracy: 98.14286041259766\n",
      "Iteration: 15000, Loss: 0.0034608507994562387, Accuracy: 97.54762268066406\n",
      "Iteration: 15500, Loss: 0.0017694958951324224, Accuracy: 98.10713958740234\n",
      "Iteration: 16000, Loss: 0.000894463446456939, Accuracy: 98.04762268066406\n",
      "Iteration: 16500, Loss: 0.011577545665204525, Accuracy: 98.19047546386719\n",
      "Iteration: 17000, Loss: 0.0016729321796447039, Accuracy: 98.0952377319336\n",
      "Iteration: 17500, Loss: 0.0005762823857367039, Accuracy: 98.25\n",
      "Iteration: 18000, Loss: 0.0017301358748227358, Accuracy: 98.13095092773438\n",
      "Iteration: 18500, Loss: 0.001287076622247696, Accuracy: 98.27381134033203\n",
      "Iteration: 19000, Loss: 0.0003724440175574273, Accuracy: 98.08333587646484\n",
      "Iteration: 19500, Loss: 0.0008647829527035356, Accuracy: 98.23809814453125\n",
      "[tensor(0.0203, grad_fn=<NllLossBackward0>), tensor(0.0172, grad_fn=<NllLossBackward0>), tensor(0.0052, grad_fn=<NllLossBackward0>), tensor(0.0308, grad_fn=<NllLossBackward0>), tensor(0.0194, grad_fn=<NllLossBackward0>), tensor(0.0379, grad_fn=<NllLossBackward0>), tensor(0.0464, grad_fn=<NllLossBackward0>), tensor(0.0108, grad_fn=<NllLossBackward0>), tensor(0.0242, grad_fn=<NllLossBackward0>), tensor(0.0107, grad_fn=<NllLossBackward0>), tensor(0.0443, grad_fn=<NllLossBackward0>), tensor(0.0060, grad_fn=<NllLossBackward0>), tensor(0.0080, grad_fn=<NllLossBackward0>), tensor(0.0051, grad_fn=<NllLossBackward0>), tensor(0.0072, grad_fn=<NllLossBackward0>), tensor(0.1158, grad_fn=<NllLossBackward0>), tensor(0.0038, grad_fn=<NllLossBackward0>), tensor(0.0166, grad_fn=<NllLossBackward0>), tensor(0.0012, grad_fn=<NllLossBackward0>), tensor(0.0383, grad_fn=<NllLossBackward0>), tensor(0.0017, grad_fn=<NllLossBackward0>), tensor(0.0078, grad_fn=<NllLossBackward0>), tensor(0.0107, grad_fn=<NllLossBackward0>), tensor(0.0031, grad_fn=<NllLossBackward0>), tensor(0.0108, grad_fn=<NllLossBackward0>), tensor(0.0037, grad_fn=<NllLossBackward0>), tensor(0.0061, grad_fn=<NllLossBackward0>), tensor(0.0048, grad_fn=<NllLossBackward0>), tensor(0.0023, grad_fn=<NllLossBackward0>), tensor(0.0035, grad_fn=<NllLossBackward0>), tensor(0.0018, grad_fn=<NllLossBackward0>), tensor(0.0009, grad_fn=<NllLossBackward0>), tensor(0.0116, grad_fn=<NllLossBackward0>), tensor(0.0017, grad_fn=<NllLossBackward0>), tensor(0.0006, grad_fn=<NllLossBackward0>), tensor(0.0017, grad_fn=<NllLossBackward0>), tensor(0.0013, grad_fn=<NllLossBackward0>), tensor(0.0004, grad_fn=<NllLossBackward0>), tensor(0.0009, grad_fn=<NllLossBackward0>)] [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500] [tensor(97.1667), tensor(97.4286), tensor(97.2619), tensor(97.6071), tensor(97.6071), tensor(97.5000), tensor(97.4048), tensor(97.3333), tensor(97.6310), tensor(97.8810), tensor(97.4524), tensor(97.7738), tensor(97.6667), tensor(97.8095), tensor(97.9405), tensor(97.1429), tensor(98.), tensor(97.8333), tensor(98.0833), tensor(97.8690), tensor(97.9405), tensor(97.8214), tensor(98.0357), tensor(98.0476), tensor(97.9881), tensor(97.7976), tensor(98.2143), tensor(97.9881), tensor(98.1429), tensor(97.5476), tensor(98.1071), tensor(98.0476), tensor(98.1905), tensor(98.0952), tensor(98.2500), tensor(98.1310), tensor(98.2738), tensor(98.0833), tensor(98.2381)]\n",
      "CPU times: user 19min 7s, sys: 13.6 s, total: 19min 20s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lost_list, iteration_list, accuracy_list = train_LSTMWithLinearOutput_model_on_images(\n",
    "    lstm_with_linear_output,\n",
    "    process_digits_data,\n",
    "    number_of_epochs)\n",
    "\n",
    "print(lost_list, iteration_list, accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980b40a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
